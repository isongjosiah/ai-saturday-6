{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "260c8ef97786b85c8ba8e76ab1a5bc37",
     "grade": false,
     "grade_id": "cell-99de9bbd95a287b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font color=red>For the submission of this assignment, you should create the following folder structure: \"FIRSTNAME_LASTNAME/hw01/hw01.ipynb\". Then, zip your files and submit on google classroom.</font> \n",
    "\n",
    "<img src='folder.png'/>\n",
    "\n",
    "<font color=red>!!! PLEASE DON'T DELETE ANY EMPTY CELLS !!!</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "328d0b578542b5769c752456b0c209d2",
     "grade": false,
     "grade_id": "cell-10bdf1b6586e065d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "In this homework we are going to apply linear regression to two different problems. We'll begin by guiding you through predicting job satisfaction and the desire to be a manager among developers based on survey data. Once that's done, you will model candy preference based on composition and food science properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8090b3f5e08d12e4eef4572733937f67",
     "grade": false,
     "grade_id": "cell-ad59cdc449b28241",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import math\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from testing.testing import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "799bafbc798c721d5a3fd0be6757773c",
     "grade": false,
     "grade_id": "cell-82dd6193ed028267",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Developers! Developers! Developers!\n",
    "\n",
    "The data from this question is based on the [2019 StackOverflow Survey](https://insights.stackoverflow.com/survey/2019); accordingly, the subset bundled with this assignment is also released under the Open Database License (ODbL) v1.0.\n",
    "\n",
    "The data was made by selecting some columns from the original dataset, only retaining rows from people who described themselves as \"a developer by profession\", and replaced long responses with shorter strings. Lets begin by examining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7e8a96f89c62fbde812587a2b6916f6",
     "grade": false,
     "grade_id": "cell-4032ae1cee94369a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age': '22',\n",
      " 'CareerSat': 'vs',\n",
      " 'CodeRevHrs': 'NA',\n",
      " 'ConvertedComp': '61000',\n",
      " 'Country': 'United States',\n",
      " 'Dependents': 'n',\n",
      " 'DevEnvironVSC': 'y',\n",
      " 'DevTypeFullStack': 'n',\n",
      " 'EdLevel': 'bachelors',\n",
      " 'EduOtherMOOC': 'y',\n",
      " 'EduOtherSelf': 'y',\n",
      " 'Extraversion': 'y',\n",
      " 'GenderIsMan': 'y',\n",
      " 'Hobbyist': 'n',\n",
      " 'MgrIdiot': 'very',\n",
      " 'MgrWant': 'n',\n",
      " 'OpSys': 'win',\n",
      " 'OpenSourcer': 'never',\n",
      " 'OrgSize': '100-499',\n",
      " 'Respondent': '4',\n",
      " 'Student': 'n',\n",
      " 'UndergradMajorIsComputerScience': 'y',\n",
      " 'UnitTestsProcess': 'n',\n",
      " 'WorkWeekHrs': '80',\n",
      " 'YearsCode': '3',\n",
      " 'YearsCodePro': '0'}\n",
      "### TESTING read_csv: PASSED 2/2\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_csv_test(read_csv):\n",
    "    headers, rows = read_csv()\n",
    "    test.equal(len(rows), 65679)\n",
    "    test.equal(len(headers), 26)\n",
    "\n",
    "    # Print a row:\n",
    "    pprint(dict(zip(headers, rows[0])))\n",
    "    \n",
    "@test\n",
    "def read_csv(fn=\"eggs.csv.gz\"):\n",
    "    \"\"\"read the GZipped CSV data and split it into headers and newlines.\n",
    "    \n",
    "    kwargs:\n",
    "        fn : str -- .csv.gz file to read\n",
    "    \n",
    "    returns: Tuple[headers, body] where\n",
    "      headers : Tuple[str] -- the CSV headers\n",
    "      body : List[Tuple[str,...]] -- the CSV body\n",
    "    \"\"\"\n",
    "    with gzip.open(fn, 'rt', newline=\"\", encoding='utf-8') as f:\n",
    "        csvobj = csv.reader(f)\n",
    "        headers = next(csvobj)\n",
    "        return headers, [tuple(row) for row in csvobj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "056aff0367b031888323a2d6b84235b3",
     "grade": false,
     "grade_id": "cell-5069226b2bf31182",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Our task is to predict:\n",
    "\n",
    "1. if respondents are managers or want to be a manager in the future (`MgrWant` is `y`), and\n",
    "2. if respondents are satisfied with their career (`CareerSat` is `vs` or `ss`)\n",
    "\n",
    "based on the remaining rows. We have bolded these rows in the table below.\n",
    "\n",
    "Before we can use linear regression, we must convert this into numeric data. This is the core challenge of this problem; Here's a table of rows and what they mean:\n",
    "\n",
    "\n",
    "| Column | Sample | Does/is the respondent... | Type/Values |\n",
    "| --- |:--- |:--- |:--- |\n",
    "| **CareerSat** | 'vs' | satisfied with their career? | (`vd`, `sd`, `ne`, `NA`, `ss`, `vs`) -- corresponding to ({very, slightly}, {satisfied, dissatisfied}), neutral, and not applicable |\n",
    "| **MgrWant** | 'n' | ...want to be a manager? | boolean |\n",
    "| Age    | '22'   | age | integer     |\n",
    "| CodeRevHrs | '2' | hours a week spent reviewing code | integer |\n",
    "| ConvertedComp | '61000' | yearly compensation in 2019 USD | integer |\n",
    "| Country | 'United States' | lives in country | string _(ignore in regression)_ |\n",
    "| Dependents | 'n' | ...have children or other dependents. | boolean |\n",
    "| DevEnvironVSC | 'y' | ...use Visual Studio Code | boolean |\n",
    "| DevTypeFullStack | 'n' | ...identify as a full-stack developer | boolean |\n",
    "| EdLevel | 'bachelors' | maximum education level | (`other`, `bachelors`, `masters`, `doctoral`) |\n",
    "| EduOtherMOOC | 'y' | ...ever taken a Massively Open Online Course | boolean |\n",
    "| EduOtherSelf | 'y' | ...ever taught themselves a new platform | boolean |\n",
    "| Extraversion | 'y' | ...prefer in-person meetings to online meetings | boolean |\n",
    "| GenderIsMan | 'y' | ...male | boolean |\n",
    "| Hobbyist | 'n' | ...write code as a hobby? | boolean |\n",
    "| MgrIdiot | 'very' | ...think their manager knows what they are doing? | (`NA`, `not`, `some`, `very`), in order of increasing confidence |\n",
    "| OpSys | 'win' | which OS do they use? | (`win`, `mac`, `tux`, `NA`), for (Windows, Mac OSX, Linux-like, NA) |\n",
    "| OpenSourcer | 'Never' | ...contribute to open-source projects? | (`never`, `year`, `month-year`, `month`), in increasing order of frequency |\n",
    "| OrgSize | '100-499' | number of employees in organization? | (`NA`, `1`, `2-9`, `10-19`, `20-99`, `100-499`, `500-999`, `1,000-4,999`, `5,000-9,999`, `10,000+`) |\n",
    "| Respondent | '4' | respondent ID from original data | integer _(ignore in regression)_ |\n",
    "| Student | 'n' | ...currently a student? | boolean |\n",
    "| UndergradMajorIsComputerScience | 'y' | ...majored in CS? | boolean |\n",
    "| UnitTestsProcess | 'n' | ...use unit tests in their job? | boolean |\n",
    "| WorkWeekHrs | '80' | hours a week worked | integer |\n",
    "| YearsCode | 3 | years since first programming | integer |\n",
    "| YearsCodePro | 0 | years programming professionally | integer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9025e45ffb02e92b3872e95310bd97ca",
     "grade": false,
     "grade_id": "cell-2c2fad4f522e2d85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Type conversion\n",
    "\n",
    "Now for the slow data-cleaning grind that is characteristic of work as a data scientist. We begin by writing type coercion functions: functions that convert each column type into a `float` value for use in linear regression. All input values are `str`.\n",
    "\n",
    "The column types are:\n",
    "\n",
    " - _boolean_ : `y`/`NA`/`n` assigned to `+1.0`/`0.0`/`0.0`\n",
    " - _integer_ : convert to `float`, preserving value. `NA` equals `0.0`. \n",
    " - _string_ : not included in regression; we'll use it later\n",
    " - CareerSat: Map (`vd`, `sd`, `ne`, `NA`, `ss`, `vs`) to (-2.0, -1.0, 0.0, 0.0, 1.0, 2.0)\n",
    " - EdLevel: Map (`other`, `bachelors`, `masters`, `doctoral`) to (0.0, 1.0, 1.5, 2.0)\n",
    " - MgrIdiot: Map (`NA`, `not`, `some`, `very`) to (-1.0, -1.0, 0.0, 1.0)\n",
    " - OpSys: This is a category variable, we will split this into three columns (one for each possible value) and set 1.0 in the corresponding column. This is called a [one-hot encoding](https://en.wikipedia.org/wiki/One-hot). (Don't write a conversion function in this step.)\n",
    " - OpenSourcer : Map (`never`, `year`, `month-year`, `month`) to (0.0, 0.5, 1.0, 2.0)\n",
    " - OrgSize: Map each range \"$a$-$b$\" to the value $ln(a)$. Treat `NA` as `ln(1.0) = 0`. We are converting an exponentially distributed range to a linearly distributed one.\n",
    "\n",
    "All your conversion functions must throw an exception if you encounter an unexpected value. As an example, we give you the boolean conversion function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85e9f19890d89b838dd3c314eac45709",
     "grade": false,
     "grade_id": "cell-40127e121c4fb868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_boolean: PASSED 4/4\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def type_boolean_test(type_boolean):\n",
    "    test.true(isinstance(type_boolean(\"y\"), float))\n",
    "    test.equal(type_boolean(\"y\"), 1.0)\n",
    "    test.equal(type_boolean(\"n\"), 0.0)\n",
    "    test.exception(lambda: type_boolean(\"5\"))\n",
    "\n",
    "@test\n",
    "def type_boolean(c):\n",
    "    if c == \"y\": return 1.0\n",
    "    elif c == \"n\": return 0.0\n",
    "    elif c == \"NA\": return 0.0\n",
    "    raise ValueError(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79fae651176841a9199886bd2f0a0221",
     "grade": false,
     "grade_id": "cell-96227d931c90d783",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now fill in these functions according to specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c875bf3ffe0965a4563dfcbe2c9539ab",
     "grade": false,
     "grade_id": "cell-aae1b8d2ba6edc96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_integer: PASSED 7/7\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Integer\n",
    "def type_integer_test(type_integer):\n",
    "    test.true(isinstance(type_integer(\"5\"), float))\n",
    "    test.equal(type_integer(\"3\"), 3.0)\n",
    "    test.equal(type_integer(\"0\"), 0.0)\n",
    "    test.equal(type_integer(\"-4\"), -4.0)\n",
    "    test.equal(type_integer(\"NA\"), 0.0)\n",
    "    test.equal(type_integer(3), 3.0)\n",
    "    test.exception(lambda: type_integer(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_integer(c):\n",
    "    if c == \"NA\": return 0.0\n",
    "    else : return float(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "392111797c043525fe3210167b058bb9",
     "grade": true,
     "grade_id": "cell-f87a1ca10bd29d5d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(c, converter):\n",
    "    if c in converter: return converter[c]\n",
    "    else: raise ValueError(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0522e747b707ecf1f4102c2c259ca74",
     "grade": false,
     "grade_id": "cell-f73b864471e478c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_CareerSat: PASSED 7/7\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CareerSat\n",
    "def type_CareerSat_test(type_CareerSat):\n",
    "    test.true(isinstance(type_CareerSat(\"vd\"), float))\n",
    "    test.equal(type_CareerSat(\"sd\"), -1.0)\n",
    "    test.equal(type_CareerSat(\"ne\"), 0.0)\n",
    "    test.equal(type_CareerSat(\"NA\"), 0.0)\n",
    "    test.equal(type_CareerSat(\"ss\"), 1.0)\n",
    "    test.equal(type_CareerSat(\"vs\"), 2.0)\n",
    "    test.exception(lambda: type_CareerSat(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_CareerSat(c):\n",
    "    converter = {\"vd\": -2.0, \"sd\": -1.0, \"ne\": 0.0, \"NA\": 0.0, \"ss\":1.0, \"vs\":2.0}\n",
    "    return mapper(c, converter)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9f252f101155d2cb19aa40fa7c808fd",
     "grade": true,
     "grade_id": "cell-453a9ecd45f052e3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49a14772be93354d5e7d35b0c8d86f16",
     "grade": false,
     "grade_id": "cell-9c7b8d5b019a0561",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_EdLevel: PASSED 5/5\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EdLevel\n",
    "def type_EdLevel_test(type_EdLevel):\n",
    "    test.true(isinstance(type_EdLevel(\"other\"), float))\n",
    "    test.equal(type_EdLevel(\"bachelors\"), 1.0)\n",
    "    test.equal(type_EdLevel(\"masters\"), 1.5)\n",
    "    test.equal(type_EdLevel(\"doctoral\"), 2.0)\n",
    "    test.exception(lambda: type_EdLevel(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_EdLevel(c):\n",
    "    converter = {\"other\": 0.0, \"bachelors\": 1.0, \"masters\": 1.5, \"doctoral\": 2.0}\n",
    "    return mapper(c, converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04b0d892432fa68dc7f0e30972a58ddf",
     "grade": true,
     "grade_id": "cell-97e66c7b439dfde6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "140943384c580ae278556a75c41af2e5",
     "grade": false,
     "grade_id": "cell-166e0418d37d3944",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_MgrIdiot: PASSED 5/5\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MgrIdiot\n",
    "def type_MgrIdiot_test(type_MgrIdiot):\n",
    "    test.true(isinstance(type_MgrIdiot(\"NA\"), float))\n",
    "    test.equal(type_MgrIdiot(\"not\"), -1.0)\n",
    "    test.equal(type_MgrIdiot(\"some\"), 0.0)\n",
    "    test.equal(type_MgrIdiot(\"very\"), 1.0)\n",
    "    test.exception(lambda: type_MgrIdiot(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_MgrIdiot(c):\n",
    "    converter = {\"NA\":-1.0, \"not\": -1.0, \"some\": 0.0, \"very\": 1.0}\n",
    "    return mapper(c, converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fb90e27f8e3b554a8918eaff20a7cad",
     "grade": true,
     "grade_id": "cell-cb464f3363aaa43d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a07acc39bda9d9a74cd234e994d5378",
     "grade": false,
     "grade_id": "cell-88c02d89e84925bc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_OpenSourcer: PASSED 5/5\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OpenSourcer\n",
    "def type_OpenSourcer_test(type_OpenSourcer):\n",
    "    test.true(isinstance(type_OpenSourcer(\"never\"), float))\n",
    "    test.equal(type_OpenSourcer(\"year\"), 0.5)\n",
    "    test.equal(type_OpenSourcer(\"month-year\"), 1.0)\n",
    "    test.equal(type_OpenSourcer(\"month\"), 2.0)\n",
    "    test.exception(lambda: type_OpenSourcer(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_OpenSourcer(c):\n",
    "    converter = {\"never\":0.0, \"year\":0.5, \"month-year\":1.0, \"month\":2.0}\n",
    "    return mapper(c, converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0960bc6fb3c27a66bb6ee19e40e21671",
     "grade": true,
     "grade_id": "cell-4bca61cad65f1f02",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c14423926362152810589916a3434ce",
     "grade": false,
     "grade_id": "cell-77da5a6eca3ea5ae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING type_OrgSize: PASSED 6/6\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OrgSize\n",
    "def type_OrgSize_test(type_OrgSize):\n",
    "    test.true(isinstance(type_OrgSize(\"1\"), float))\n",
    "    test.equal(type_OrgSize(\"NA\"), 0)\n",
    "    test.equal(type_OrgSize(\"2-9\"), 0.6931471805599453)\n",
    "    test.equal(type_OrgSize(\"100-499\"), 4.605170185988092)\n",
    "    test.equal(type_OrgSize(\"10,000+\"), 9.210340371976184)\n",
    "    test.exception(lambda: type_OrgSize(\"yes\"))\n",
    "\n",
    "@test\n",
    "def type_OrgSize(c):\n",
    "    if c == \"NA\": return 0\n",
    "    else:\n",
    "        a = c.split(\"-\")[0]\n",
    "        try:\n",
    "            return math.log(float(a))\n",
    "        except ValueError:\n",
    "            a = a.replace(\"+\", \"\")\n",
    "            a = a.replace(\",\", \"\")\n",
    "            return math.log(float(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa53f6d054d26533d261f4ea0fec8d64",
     "grade": true,
     "grade_id": "cell-0fe6130385ba0f37",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_converter(body, function, col):\n",
    "    for i in range(len(body)):\n",
    "        body[i][col] = function(body[i][col])\n",
    "        \n",
    "def encoder(body):\n",
    "    for i in range(len(body)):\n",
    "        if body[i][19] == 'win':\n",
    "            body[i].append(1.0)\n",
    "            body[i].append(0.0)\n",
    "            body[i].append(0.0)\n",
    "        elif body[i][19] == 'mac':\n",
    "            body[i].append(0.0)\n",
    "            body[i].append(1.0)\n",
    "            body[i].append(0.0)\n",
    "        elif body[i][19] == 'tux':\n",
    "            body[i].append(0.0)\n",
    "            body[i].append(0.0)\n",
    "            body[i].append(1.0)\n",
    "        else:\n",
    "            body[i].append(0.0)\n",
    "            body[i].append(0.0)\n",
    "            body[i].append(0.0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e4c5fc8adf6809bcb1b0c999ee6a662",
     "grade": false,
     "grade_id": "cell-92a5cb7a1a52ce5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we deal with OpSys; from the one column in the source, create three columns (called OpSysWin, OpSysMac, and OpSysTux, corresponding to the values win, mac, tux.) For each row, at most one of the cells must be 1.0, and the others must be 0.0. If the value in the cell is NA, BSD, or something else, then all the cells must be 0.0.\n",
    "\n",
    "This is called a one-hot encoding and is a common way to handle category variables.\n",
    "\n",
    "In convert_data_stackoverflow, you should:\n",
    "\n",
    "Encode OpSys as the one-hot encoding discussed above\n",
    "Remove the Respondent and Country, the two columns not used.\n",
    "Convert other columns using the appropriate functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b09d2bf1c1810e209070945346a8188d",
     "grade": false,
     "grade_id": "cell-427049e8b96505ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING convert_data_stackoverflow: PASSED 5/6\n",
      "# 2\t: Assertion failed\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_data_stackoverflow_test(convert_data_stackoverflow):\n",
    "    headers, rows = convert_data_stackoverflow(*read_csv())\n",
    "    # Correct number of rows:\n",
    "    test.equal(len(rows), 65679)\n",
    "    \n",
    "    # If this test fails, your headers are incorrect:\n",
    "    test.equal(set(headers), {'CareerSat', 'MgrWant', 'Age', 'CodeRevHrs', 'ConvertedComp', 'Dependents', 'DevEnvironVSC', 'DevTypeFullStack', 'EdLevel', 'EduOtherMOOC', 'EduOtherSelf', 'Extraversion', 'GenderIsMan', 'Hobbyist', 'MgrIdiot', 'OpSysWin', 'OpSysMac', 'OpSysTux', 'OpenSourcer', 'OrgSize', 'Student', 'UndergradMajorIsComputerScience', 'UnitTestsProcess', 'WorkWeekHrs', 'YearsCode', 'YearsCodePro'})\n",
    "    # Type check:\n",
    "    test.true(all(all(isinstance(v, float) for v in r) for r in rows))\n",
    "    # Operating System columns:\n",
    "    for row in rows:\n",
    "        d = dict(zip(headers, row))\n",
    "        if sorted([d[\"OpSysWin\"], d[\"OpSysMac\"], d[\"OpSysTux\"]]) not in [[.0, .0, 1.], [0.]*3]:\n",
    "            test.true(False)\n",
    "            break\n",
    "    else:\n",
    "        test.true(\"There is correctly at most one OpSys* column set to 1.0\")\n",
    "    \n",
    "    # More direct tests\n",
    "    test.equal(dict(zip(headers, rows[-2])), {'CareerSat': -1.0, 'MgrWant': 1.0, 'Age': 0.0, 'CodeRevHrs': 5.0, 'ConvertedComp': 588012.0, 'Dependents': 1.0, 'DevEnvironVSC': 1.0, 'DevTypeFullStack': 1.0, 'EdLevel': 1.5, 'EduOtherMOOC': 0.0, 'EduOtherSelf': 0.0, 'Extraversion': 0.0, 'GenderIsMan': 1.0, 'Hobbyist': 1.0, 'MgrIdiot': -1.0, 'OpSysWin': 0.0, 'OpSysMac': 0.0, 'OpSysTux': 1.0, 'OpenSourcer': 0.0, 'OrgSize': 4.605170185988092, 'Student': 1.0, 'UndergradMajorIsComputerScience': 1.0, 'UnitTestsProcess': 1.0, 'WorkWeekHrs': 40.0, 'YearsCode': 10.0, 'YearsCodePro': 8.0})\n",
    "    test.equal(dict(zip(headers, rows[-1])), {'CareerSat': -1.0, 'MgrWant': 0.0, 'Age': 33.0, 'CodeRevHrs': 0.0, 'ConvertedComp': 22915.0, 'Dependents': 0.0, 'DevEnvironVSC': 0.0, 'DevTypeFullStack': 0.0, 'EdLevel': 1.0, 'EduOtherMOOC': 0.0, 'EduOtherSelf': 0.0, 'Extraversion': 1.0, 'GenderIsMan': 1.0, 'Hobbyist': 0.0, 'MgrIdiot': -1.0, 'OpSysWin': 0.0, 'OpSysMac': 0.0, 'OpSysTux': 1.0, 'OpenSourcer': 2.0, 'OrgSize': 2.995732273553991, 'Student': 0.0, 'UndergradMajorIsComputerScience': 1.0, 'UnitTestsProcess': 1.0, 'WorkWeekHrs': 48.0, 'YearsCode': 9.0, 'YearsCodePro': 5.0})\n",
    "\n",
    "@test\n",
    "def convert_data_stackoverflow(headers, data):\n",
    "    \"\"\"convert the data into \n",
    "    \n",
    "    args:\n",
    "        header : List[str] -- the header for each column in the CSV\n",
    "        data : List[Tuple[str]] -- the CSV data, where each inner list corresponds to a row in the CSV file.\n",
    " \n",
    "    returns: Tuple[headers, body] where\n",
    "      headers : List[str] -- the new headers, dropping the Country and Respondent headers and expanding \n",
    "      body : List[List[str,...]] -- the CSV body\n",
    "    \"\"\"\n",
    "    # drop the defined columns\n",
    "    headers.remove('Country')\n",
    "    headers.remove('Respondent')\n",
    "    \n",
    "    # convert data into List[List[str,..]]\n",
    "    body = []\n",
    "    for x in data:\n",
    "        x = list(x)\n",
    "        # remove respondent column\n",
    "        x.pop(0)\n",
    "        # remove country column\n",
    "        x.pop(4)\n",
    "        body.append(x)\n",
    "\n",
    "    \n",
    "    # extending the body\n",
    "    os = [\"OpSysWin\", \"OpSysMac\",\"OpSysTux\"]\n",
    "    headers.extend(os)\n",
    "    \n",
    "    # fill in the values of the ohe\n",
    "    encoder(body)\n",
    "    \n",
    "    # remove the os column\n",
    "    headers.remove('OpSys')\n",
    "    \n",
    "    #remove the os column\n",
    "    for x in body:\n",
    "        x.pop(19)\n",
    "    \n",
    "        \n",
    "    # converting to appropriate types\n",
    "    type_converter(body, type_CareerSat, 0)\n",
    "    type_converter(body, type_boolean, 1)\n",
    "    type_converter(body, type_boolean, 2)\n",
    "    type_converter(body, type_OpenSourcer, 3)\n",
    "    type_converter(body, type_boolean, 4)\n",
    "    type_converter(body, type_EdLevel, 5)\n",
    "    type_converter(body, type_boolean, 6)\n",
    "    type_converter(body, type_boolean, 7)\n",
    "    type_converter(body, type_boolean, 8)\n",
    "    type_converter(body, type_OrgSize, 9)\n",
    "    type_converter(body, type_boolean, 10)\n",
    "    type_converter(body, type_integer, 11)\n",
    "    type_converter(body, type_integer, 12)\n",
    "    type_converter(body, type_MgrIdiot, 13)\n",
    "    type_converter(body, type_integer, 14)\n",
    "    type_converter(body, type_integer, 15)\n",
    "    type_converter(body, type_integer, 16)\n",
    "    type_converter(body, type_boolean, 17)\n",
    "    type_converter(body, type_boolean, 18)\n",
    "    type_converter(body, type_boolean, 19)\n",
    "    type_converter(body, type_integer, 20)\n",
    "    type_converter(body, type_boolean, 21)\n",
    "    type_converter(body, type_boolean, 22)\n",
    "    \n",
    "    \n",
    "    return headers, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e7f0d134eb90791077546f3d58e2691",
     "grade": true,
     "grade_id": "cell-de43a288e13ee1f0",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3113cc23dc56db3e45fe0a1d9dbc79df",
     "grade": true,
     "grade_id": "cell-f9b1ad79f450610b",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "038e86798e8b91184c5c74a3bf5cc897",
     "grade": false,
     "grade_id": "cell-ce7d932ad18c3ece",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Splitting Data¶\n",
    "\n",
    "Now we prepare the converted data for regression. In this step, we:\n",
    "\n",
    "split this into training and validation sets,\n",
    "convert it to a Numpy ndarray with underlying type np.float32,\n",
    "split each set into the predicted columns and the feature columns.\n",
    "We will save the first 20% of the dataset (rounded down) as the validation set and keep the remaining as the training set. (Note that it is common practice to randomize the dataset; this has already been done. Don't shuffle the dataset for this assignment.)\n",
    "\n",
    "Ensure that the underlying type of the ndarray is np.float32, not the default np.float64. We do not need the added precision of 64-bit floating point numbers for this problem, and using the smaller numbers will speed up computation and reduce the amount of memory we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd23ff79769c2fe95f29506eaef4048d",
     "grade": false,
     "grade_id": "cell-5e7641855fc288c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING split_data: PASSED 6/6\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_data_test(split_data):\n",
    "    headers, rows = convert_data_stackoverflow(*read_csv())\n",
    "    l = len(rows)\n",
    "    \n",
    "    val, train = split_data(rows)\n",
    "    test.equal(len(val), l // 5)\n",
    "    test.true(isinstance(val, np.ndarray))\n",
    "    test.equal(val.dtype, np.float32)\n",
    "    test.equal(len(train), l - (l // 5))\n",
    "    test.true(isinstance(train, np.ndarray))\n",
    "    test.equal(train.dtype, np.float32)\n",
    "\n",
    "@test\n",
    "def split_data(data):\n",
    "    \"\"\"split the data into training and validation sets, and convert them to np.ndarray. (Step 1 and 2 above.)\n",
    "\n",
    "    args:\n",
    "        data : List[List[str]] -- the CSV data, where each inner list corresponds to a row in the CSV file.\n",
    "\n",
    "    returns: Tuple[val, train] where\n",
    "      val  : np.ndarray[num_val_rows, num_features] -- the first 20% of the dataset (rounded down)\n",
    "      train : np.ndarray[num_train_rows, num_features] -- the remaining rows from data\n",
    "    \n",
    "    Ensure that the underlying type of the output is np.float32, not the default np.float64.\n",
    "    \"\"\"\n",
    "\n",
    "    split_at = math.floor((20 * len(data))/100)\n",
    "    data = np.array(data, dtype=\"float32\")\n",
    "    val = data[0:split_at]\n",
    "    train = data[split_at:]\n",
    "    \n",
    "    return val, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a16fc41f50df908fd524b5eb12928242",
     "grade": true,
     "grade_id": "cell-482964e226dd3e40",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dd0e3ca599eb6911464863b8de5444e",
     "grade": true,
     "grade_id": "cell-fc9eb908ff585530",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e726052e16383c8a00944f3703296a6",
     "grade": true,
     "grade_id": "cell-384d390c2981d3cd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c33b486bc020fc7642ba3e5fe5c263c9",
     "grade": false,
     "grade_id": "cell-4f12ddeb401e56b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING separate_objective: PASSED 10/10\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def separate_objective_test(separate_objective):\n",
    "    headers, rows = convert_data_stackoverflow(*read_csv())\n",
    "    val, train = split_data(rows)\n",
    "\n",
    "    for subset in [val, train]:\n",
    "        subset_headers, subset_features, subset_objectives = separate_objective(headers, subset, [\"CareerSat\", \"MgrWant\"])\n",
    "\n",
    "        test.true(isinstance(subset_objectives, tuple))\n",
    "        test.equal(len(subset_objectives), 2)\n",
    "        test.true(\"CareerSat\" not in subset_headers)\n",
    "        test.true(\"MgrWant\" not in subset_headers)\n",
    "        test.equal(subset_features.shape[1], 24)\n",
    "\n",
    "@test\n",
    "def separate_objective(headers, data, objectives):\n",
    "    \"\"\"split the objective columns from the headers and data. (Step 1 and 2 above.)\n",
    "\n",
    "    args:\n",
    "        headers    : List[str] -- the headers for the data, used to find the objective columns from the data array\n",
    "        data       : np.ndarray[num_rows, num_columns] -- the data\n",
    "        objectives : the columns to extract from the data\n",
    "\n",
    "    returns: Tuple[o_headers, o_features, o_objectives] where\n",
    "      o_headers  : List[str] -- a list of headers without the objective columns\n",
    "      o_features : np.ndarray[num_train_rows, num_features] -- the remaining columns from data. (num_features = num_columns - len(objectives))\n",
    "      o_objectives : Tuple[np.ndarray[num_train_rows], ...] -- a list of objective columns from the data, each element is a 1-dimensional np.ndarray corresponding to the entry in objectives.\n",
    "     \"\"\"\n",
    "    # remove the objectives headers\n",
    "    for col in objectives:\n",
    "        if col in headers:\n",
    "            headers.remove(col)\n",
    "\n",
    "    o_headers = headers  \n",
    "    subset = [np.array(data[:, 0]), np.array(data[:, 1])]\n",
    "    \n",
    "    #seperating the objective data\n",
    "    o_features = np.array(data[:, 2:], dtype=\"float32\")\n",
    "    o_objectives = tuple(subset)\n",
    "    return o_headers, o_features, o_objectives\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a54570397fca918dc565aa20cf25a23",
     "grade": true,
     "grade_id": "cell-a40db5afd59015d3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1136aac9abdb43f7fbc5637511fe4fb5",
     "grade": true,
     "grade_id": "cell-d059365d4c3f7e21",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4196eace896389cfe10849e8139da73f",
     "grade": true,
     "grade_id": "cell-98751e03aa148e6e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98c3b73b3cc6334f4243a293d8e844a0",
     "grade": true,
     "grade_id": "cell-afd577296c8c4049",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cca884e8c90ca0d3d7a31c61b664af7",
     "grade": true,
     "grade_id": "cell-e92c2a9fa4098383",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cbbd8d8ab2fb921dd711256a6185106",
     "grade": false,
     "grade_id": "cell-d7c412b54dd7438e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Linear Regression\n",
    "\n",
    "Now you will finally implement a linear regression. As a reminder, linear regression models the data as\n",
    "\n",
    "$$\\mathbf y = \\mathbf X\\mathbf \\beta + \\mathbf \\epsilon$$\n",
    "\n",
    "where $\\mathbf y$ is a vector of outputs, $\\mathbf X$ is also known as the design matrix, $\\mathbf \\beta$ is a vector of parameters, and $\\mathbf \\epsilon$ is noise. We will be estimating $\\mathbf \\beta$ using the [Ordinary Least Squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) approach.\n",
    "\n",
    "Hints:\n",
    "\n",
    " 1. Use `np.linalg.solve` to calculate `beta` instead of inverting the matrix, which is [numerically unstable](https://math.stackexchange.com/a/1622654).\n",
    " 2. You should add `1e-4*np.eye(...)` to the coefficient matrix to prevent singular value errors. Our test cases assume the coefficient `1e-4`, which is **not** equal to `np.exp(-4)`.\n",
    " 3. Do not include a bias term/constant column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "952f70383471324324ad24cc0c42327a",
     "grade": false,
     "grade_id": "cell-7f6323512495e235",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    \"\"\" Perform linear regression and predict the output on unseen examples. \n",
    "    \n",
    "    attributes: \n",
    "        beta (np.ndarray) : vector containing parameters for the features\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.beta = []\n",
    "\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\" Train the linear regression model by computing the estimate of the parameters\n",
    "        You should store the model parameters in self.beta, overwriting parameters as necessary.\n",
    "\n",
    "        args: \n",
    "            X (np.ndarray[num_examples, num_columns]) : matrix of training data\n",
    "            y (np.ndarray[num_examples]) : vector of output variables\n",
    "\n",
    "        return: LinearRegression -- returns itself (for convenience)\n",
    "        \"\"\"\n",
    "        # add a 0 row in order to account for the intercept/bias\n",
    "        theta = np.linalg.inv((X.T.dot(X))).dot(X.T).dot(y)\n",
    "        theta = np.c_[10 ** -5 * np.eye(), self.beta]\n",
    "\n",
    "        self.beta = theta\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_p): \n",
    "        \"\"\" Use the learned model to predict the output of X_p\n",
    "\n",
    "        args: \n",
    "            X_p (np.ndarray[num_examples, num_columns]) matrix of test/validation data where each row corresponds to an example\n",
    "\n",
    "        return: \n",
    "            (np.ndarray[num_examples]) vector of predicted outputs\n",
    "        \"\"\"\n",
    "        shape = X_p.shape\n",
    "        y_predict = X.dot(self.beta)\n",
    "        return y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b61e562f5268fad892072b013f161bb",
     "grade": true,
     "grade_id": "cell-672fbc47a81fd50c",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fd6e46112f6a4d5eb085966e5c5e032",
     "grade": false,
     "grade_id": "cell-1ab4bd254f2b4074",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-59fbe0bdbb82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Don't remove this function; we use it for the auto-grader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_regression_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/konig/Code/hacking/ai/ml/hw01/src/jupyter-testing/testing/testing.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         print(\"\\n\".join(\n",
      "\u001b[0;32m<ipython-input-21-59fbe0bdbb82>\u001b[0m in \u001b[0;36mlinear_regression_instance_test\u001b[0;34m(linear_regression_instance)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# If you get a reference value of [10000.0, 10000.0, 10000.0, 10000.0, 10000.0], then you are applying\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#   smoothing incorrectly. You should not be adding the smoothing term to X.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Basic functionality tests:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-f62eb5eda285>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \"\"\"\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# add a 0 row in order to account for the intercept/bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home/konig/anaconda3/envs/ais6/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/konig/anaconda3/envs/ais6/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "def linear_regression_instance_test(linear_regression_instance):\n",
    "    lr = linear_regression_instance()\n",
    "\n",
    "    # If this throws a Singular Matrix error, you did not add the smoothing term:\n",
    "    # If you get a reference value of [10000.0, 10000.0, 10000.0, 10000.0, 10000.0], then you are applying\n",
    "    #   smoothing incorrectly. You should not be adding the smoothing term to X.\n",
    "    test.equal(lr.train(np.zeros((20, 5)), np.ones((20,))).beta.tolist(), [0.0]*5)\n",
    "\n",
    "    # Basic functionality tests:\n",
    "    test.equal(lr.train(np.eye(6)*(1-1e-4), np.ones((6,))).beta.round(4).tolist(), [1.0]*6)\n",
    "    test.equal(lr.train(np.array([[0., 1.], [1., 2.], [2., 3.]]), np.array([1., 2., 3.])).beta.round(4).tolist(), [0.0001, 0.9999])\n",
    "    \n",
    "# Don't remove this function; we use it for the auto-grader.\n",
    "@test\n",
    "def linear_regression_instance():\n",
    "    return LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "175ca0cc5957e9c9d1cd1f10dd808cef",
     "grade": false,
     "grade_id": "cell-1332641617b3081a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Error Functions\n",
    "\n",
    "One last part to this: linear regression minimizes the mean-squared-error. Write a function that calculates the mean mean-squared-error when given a prediction and a ground-truth vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fc34662eb2025dd689fa3c5f213a027",
     "grade": false,
     "grade_id": "cell-04a405a07265e45d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING mean_squared_error: PASSED 2/2\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error_test(mean_squared_error):\n",
    "    test.equal(mean_squared_error(np.ones(10), np.ones(10)), 0)\n",
    "    test.equal(mean_squared_error(np.ones(10), np.zeros(10)), 1)\n",
    "\n",
    "@test\n",
    "def mean_squared_error(pred, ground_truth):\n",
    "    \"\"\" calculate the mean mean-squared-error between pred and ground_truth\n",
    "    \n",
    "    args:\n",
    "      pred : np.ndarray[num_examples] -- the predictions\n",
    "      ground_truth : np.ndarray[num_examples] -- the ground truth values\n",
    "      \n",
    "    returns: float -- the average mean-squared-error between predictions and ground_truth values.\n",
    "    \"\"\"\n",
    "    summation = 0\n",
    "    n = len(pred)\n",
    "\n",
    "    for i in range(0, n):\n",
    "        diff = ground_truth[i] - pred[i]\n",
    "        diff_squared = diff ** 2\n",
    "        summation += diff_squared\n",
    "    mse = summation / n\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a58269131b0fac3a4ba31966a0c5e207",
     "grade": true,
     "grade_id": "cell-f7e120cde474aa3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e9c1c811ac772381b5a46879af314be",
     "grade": true,
     "grade_id": "cell-ea0e8123c2a2077e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be6795eb84709b9bf3a592b42607d8b5",
     "grade": false,
     "grade_id": "cell-201f1e56cfd66fd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Putting it all together\n",
    "\n",
    "And finally, lets run the entire pipeline end-to-end. You should put all the functions you have written so far together to:\n",
    "\n",
    "1. read and split the dataset,\n",
    "2. train two separate models on the training set, one to predict `MgrWant` and the other to predict `CareerSat`,\n",
    "3. perform inference on the validation set, and\n",
    "4. return the mean-squared error for each.\n",
    "\n",
    "Remember not to include both columns `MgrWant` and `CareerSat` when training models to predict either column. (i.e. when training `MgrWant`, you should not include `CareerSat` and vice-versa.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ba19036532173647779d5da49edba29",
     "grade": false,
     "grade_id": "cell-06842853a9f35c4b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eye() missing 1 required positional argument: 'N'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6609a0356af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_sat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.29104\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_regression_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\" Perform linear regression on (headers, rows), and return the MSE on the validation set for both `MgrWant` and `CareerSat`. \n",
      "\u001b[0;32m/home/konig/Code/hacking/ai/ml/hw01/src/jupyter-testing/testing/testing.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         print(\"\\n\".join(\n",
      "\u001b[0;32m<ipython-input-25-6609a0356af5>\u001b[0m in \u001b[0;36mlinear_regression_run_test\u001b[0;34m(linear_regression_run)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_regression_run_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_regression_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmse_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_sat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_mgr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.07214\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_sat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.29104\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-6609a0356af5>\u001b[0m in \u001b[0;36mlinear_regression_run\u001b[0;34m(headers, rows)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_objective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_features_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo_objective_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_objective\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-f62eb5eda285>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# add a 0 row in order to account for the intercept/bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eye() missing 1 required positional argument: 'N'"
     ]
    }
   ],
   "source": [
    "def linear_regression_run_test(linear_regression_run):\n",
    "    mse_mgr, mse_sat = linear_regression_run(*read_csv())\n",
    "    test.true(np.abs(mse_mgr - 0.07214) < 1e-4)\n",
    "    test.true(np.abs(mse_sat - 1.29104) < 1e-4)\n",
    "\n",
    "@test\n",
    "def linear_regression_run(headers, rows):\n",
    "    \"\"\" Perform linear regression on (headers, rows), and return the MSE on the validation set for both `MgrWant` and `CareerSat`. \n",
    "\n",
    "    args: \n",
    "        headers : List[str] -- headers from CSV file\n",
    "        rows : np.ndarray[num_examples, num_columns] -- data from the CSV file\n",
    "        \n",
    "    return: Tuple[MSEMgrWant, MSECareerSat], where\n",
    "        MSEMgrWant : float -- the MSE between the predictions and the ground truth values for the column `MgrWant`.\n",
    "        MSECareerSat : float -- the MSE between the predictions and the ground truth values for the column `CareerSat`.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    labels = [\"MgrWant\", \"CareerSat\"]\n",
    "    headers, rows = convert_data_stackoverflow(headers, rows)\n",
    "    val, train = split_data(rows)\n",
    "    o_headers, o_features, o_objective = separate_objective(headers, val, labels)\n",
    "    o_headers_t, o_features_t, o_objective_t = separate_objective(headers, train, labels)\n",
    "\n",
    "    for i in range(len(o_objective)):\n",
    "        lr = LinearRegression()\n",
    "        lr.train(o_features_t,o_objective_t[i])\n",
    "        y_pred = lr.predict(o_features)\n",
    "        mse = mean_squared_error(y_pred, o_objective[i])\n",
    "        output.append(mse)\n",
    "\n",
    "    return tuple(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f522cc8da161b5f8c482129136ed03c",
     "grade": true,
     "grade_id": "cell-73e5498a92a624bf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "058a13aef75d351decd212a8dbf04158",
     "grade": true,
     "grade_id": "cell-717d483d59a4f1f0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5a10872cbdddba4542dc320228efd5a",
     "grade": false,
     "grade_id": "cell-86d728278655e5d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## BONUS SECTION - Your Turn\n",
    "\n",
    "Now that we've walked through this once with a large dataset, it is your turn to do this. You will be using [FiveThirtyEight's The Ultimate Halloween Candy Power Ranking](https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking/), included (and shuffled) as `candy.csv.gz`. (The dataset is Copyright (c) 2014 ESPN Internet Ventures. Our shuffled version is released under the MIT License.)\n",
    "\n",
    "From the original documentation, here is a description of the columns:\n",
    "\n",
    "| Column | Description | type |\n",
    "| --- |:--- |:--- |\n",
    "| **`winpercent`** | The overall win percentage according to 269,000 matchups. | float |\n",
    "| `competitorname` | The bar name | string (don't use this) |\n",
    "| `chocolate` | Does it contain chocolate? | boolean (`y`, `n`) |\n",
    "| `fruity` | Is it fruit flavored? | boolean (`y`, `n`) |\n",
    "| `caramel` | Is there caramel in the candy? | boolean (`y`, `n`) |\n",
    "| `peanutalmondy` | Does it contain peanuts, peanut butter or almonds? | boolean (`y`, `n`) |\n",
    "| `nougat` | Does it contain nougat? | boolean (`y`, `n`) |\n",
    "| `crispedricewafer` | Does it contain crisped rice, wafers, or a cookie component? | boolean (`y`, `n`) |\n",
    "| `hard` | Is it a hard candy? | boolean (`y`, `n`) |\n",
    "| `bar` | Is it a candy bar? | boolean (`y`, `n`) |\n",
    "| `pluribus` | Is it one of many candies in a bag or box? | boolean (`y`, `n`) |\n",
    "| `sugarpercent` | The percentile of sugar it falls under within the data set. | float |\n",
    "| `pricepercent` | The unit price percentile compared to the rest of the set. | float |\n",
    "\n",
    "\n",
    "You must predict `winpercent` using exactly **four** other columns. Use the first 20% of the dataset as the validation set (the dataset has already been shuffled for you). As output, you should provide the names of the columns and the validation of the MSE. Your MSE must be no more than `330`.\n",
    "\n",
    "You should convert boolean columns using `type_boolean`, and `LinearRegression` to perform the regression. Don't implement a bias term/constant column. Feel free to create new helper functions as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c205f6f895a112c8a1ae605e7736f8a",
     "grade": false,
     "grade_id": "cell-03329275531e47ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "['Mr Good Bar', 'y', 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, '.31299999', '.91799998', '54.526451']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-979a42ad28d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m330.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcandy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\" predict winpercent using no more than four other columns\n",
      "\u001b[0;32m/home/konig/Code/hacking/ai/ml/hw01/src/jupyter-testing/testing/testing.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         print(\"\\n\".join(\n",
      "\u001b[0;32m<ipython-input-40-979a42ad28d0>\u001b[0m in \u001b[0;36mcandy_test\u001b[0;34m(candy)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcandy_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"candy.csv.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print((headers, mse))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"winpercent\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "def candy_test(candy):\n",
    "    headers, mse = candy(*read_csv(\"candy.csv.gz\"))\n",
    "    #print((headers, mse))\n",
    "    test.true(len(headers) == 4)\n",
    "    test.true(\"winpercent\" not in headers)\n",
    "    test.true(mse < 330.)\n",
    "\n",
    "@test\n",
    "def candy(headers, data):\n",
    "    \"\"\" predict winpercent using no more than four other columns\n",
    "    \n",
    "    args:\n",
    "        headers : List[str] -- headers read from the csv file\n",
    "        data : List[List[str]] -- data from the csv file\n",
    "\n",
    "    returns: Tuple[selected_headers, mse]\n",
    "        selected_headers : List[str] -- the headers of at most four columns used to train the model\n",
    "        mse : float -- the mean-squared error when the columns in selected_headers are used to predict `winpercent`\n",
    "    \"\"\"\n",
    "    #convert from tuple to list\n",
    "    for row in range(len(data)):\n",
    "        data[row] = list(data[row])\n",
    "    \n",
    "    # convert boolean to floats\n",
    "    for i in range(2, 10):\n",
    "        type_converter(data, type_boolean, i)\n",
    "        \n",
    "    test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf8fe4d0a576e2c84833e55c85a4bc62",
     "grade": true,
     "grade_id": "cell-96568bc1f7300400",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
